# DeepResearch Security & Reliability Audit: Healthcare Agent Backend

## Executive Summary

This audit assesses the production readiness of the healthcare-agent-backend deployment artifacts. While the project includes sophisticated observability (OpenTelemetry) and specific load-testing tooling, **critical security and functional gaps** prevent safe production deployment.

Most notably, the **Vertex AI integration is functionally impaired** by a hardcoded SDK limitation that disables streaming, which will cause the UI to hang for 5-20 seconds per request. Security is compromised by **excessive CI/CD privileges** (Admin access to artifacts) and **production code containing test logic** (monkey-patching). Operationally, the **MongoDB Free Tier (M0) architecture** faces a high risk of connection storms and NAT port exhaustion due to the lack of VPC peering support.

The report details **10 confirmed findings** and provides automated patches, a hardened CI pipeline, and a validation runbook.

> [!NOTE]
> This report was generated by Gemini Deep Research and subsequently reviewed and corrected for accuracy against the actual codebase. Corrections are marked with **[CORRECTED]** annotations where the original report contained inaccuracies.

---

## 1. Functional & Application Blockers

### 1.1 Vertex AI Streaming Hard-Disabled (SDK Limitation)

**Finding ID: APP-001**

**Severity: P1 (Functional Blocker)**

The project documentation (`docs/streaming-unsupported/diagnosis.md`) confirms that the VertexAIService in Parlant SDK v3.2.0 has `supports_streaming` hardcoded to `False`. Both `VertexAIService` and `GeminiService` adapters are affected.

**Root Cause:**

The SDK adapter for Vertex AI lacks the `StreamingTextGenerator` implementation, forcing the backend to buffer the full response. The `CannedResponseGenerator` in the SDK explicitly checks for streaming support and falls back to standard response generation when unavailable.

**Impact:**

Server-Sent Events (SSE) will not emit tokens incrementally. The user interface will appear frozen for the full duration of LLM generation (5-15s), likely resulting in user abandonment.

**Remediation:**

* **Preferred:** Upgrade to a Parlant SDK version that supports Vertex AI streaming (check release notes for >3.2.0).
* **Workaround:** Switch `production_config.py` to use `OpenAIService` if feasible, or implement a custom adapter patching `parlant.adapters.nlp.vertex_service`.

> [!IMPORTANT]
> Per `diagnosis.md`, Parlant SDK v3.2.0 disables streaming for **both** Vertex AI and Gemini services. Switching to Gemini alone will not resolve this without a newer SDK version or custom adapter.

---

## 2. Security Vulnerabilities

### 2.1 Excessive IAM Privilege in CI/CD

**Finding ID: SEC-001**

**Severity: P0 (Critical)**

The `setup-github-wif.sh` script grants `roles/artifactregistry.admin` to the GitHub Actions Service Account.

```bash
# setup-github-wif.sh:113
--role="roles/artifactregistry.admin"
```

**Impact:**

A compromised CI runner can delete all production container images or modify repository IAM policies to grant public access to proprietary code.

**Fix:** Downgrade to `roles/artifactregistry.writer`.

### 2.2 Test Logic & Monkey-Patching in Production Code

**Finding ID: SEC-002**

**Severity: P2 (High)**

The `main.py` entry point contains logic to monkey-patch `google.auth` and `httpx` if specific environment variables are set.

```python
# main.py:14
if os.environ.get("USE_VERTEX_AI") == "true" and "mock" in os.environ.get("VERTEX_AI_API_ENDPOINT", ""):
    # ... mocks google.auth.default, patches httpx.AsyncClient.request and httpx.Client.request ...
```

**Impact:**

Including test hooks in production code increases the attack surface. An attacker who can manipulate environment variables (e.g., via a compromised ConfigMap) can redirect LLM traffic to a malicious server, capturing sensitive patient PHI.

**Fix:** Move mocking logic to a separate entry point (e.g., `main_test.py`) or wrap in a strict `if TYPE_CHECKING:` or build-time flag.

### 2.3 Insecure CORS Configuration

**Finding ID: SEC-003**

**Severity: P2 (High)**

`main.py` configures CORS to allow all origins (`*`) while allowing credentials.

```python
# main.py:79
allow_origins=["*"],  # In production, specify your frontend domain
allow_credentials=True,
```

**[CORRECTED]** The original report cited line 67; the actual location is line 79 of `main.py`.

**Impact:**

Allows malicious sites to make authenticated requests to the agent on behalf of a logged-in user (CSRF-like impact).

**Fix:** Configure `allow_origins` via an environment variable `ALLOWED_ORIGINS`.

### 2.4 DEBUG Print Statements in Production Code

**Finding ID: SEC-004**

**Severity: P3 (Medium)**

`main.py` contains numerous `print("DEBUG: ...")` statements throughout the production code path (lines 15, 137-146, 265-301, 306-328, etc.). These expose internal application state, function call sequences, and server configuration to stdout.

**Impact:**

Debug output in production logs leaks implementation details and can make log analysis harder by adding noise. In containerized environments, stdout logs are typically collected by centralized logging systems and may be accessible to broader teams.

**Fix:** Replace all `print("DEBUG: ...")` statements with the structured JSON logger already configured in `production_config.py` (the `JsonFormatter` class at lines 6-13), or remove them entirely.

---

## 3. Infrastructure & Reliability Risks

### 3.1 Container UID Mismatch (CrashLoop Risk)

**Finding ID: OPS-001**

**Severity: P1 (High)**

There are two Dockerfiles in the project with different UID behaviors:

* `Dockerfile`: Creates user parlant with explicit UID **1000** (`useradd -m -u 1000 parlant`).
* `Dockerfile-GKE-Autopilot`: Creates user parlant as a **system user** (`useradd -r -g parlant`) — system users typically get UIDs in the 100-999 range.
* `setup.sh`: Generates Kubernetes manifest with `runAsUser: 999`.

**[CORRECTED]** The original report only referenced `Dockerfile`. The production deployment actually uses `Dockerfile-GKE-Autopilot`, which does **not** specify an explicit UID. This makes the UID mismatch more subtle — the system-assigned UID may or may not match 999.

**Impact:**

On GKE Autopilot (which enforces security contexts), the application may fail to write to its data directory because the file ownership doesn't match the `runAsUser` value. This can result in CrashLoopBackOff.

**Fix:** Add an explicit UID to `Dockerfile-GKE-Autopilot` (`useradd -r -g parlant -u 999 -m -d /home/parlant parlant`) to match `setup.sh`, OR update `setup.sh` to use `runAsUser: 1000` and add `-u 1000` to the `Dockerfile-GKE-Autopilot` useradd command. Choose one UID and align both files.

### ~~3.2 Load Test Script Configuration Drift~~ **[RETRACTED]**

**Finding ID: OPS-002**

**[CORRECTED]** The original report claimed that the revert function in `redeploy-for-load-testing.sh` uses `failureThreshold: 30`, creating drift with `setup.sh`'s value of 60.

**This finding is incorrect.** After code review:

* The `revert_to_production()` function (line 194-199) correctly sets `failureThreshold: 60`, matching `setup.sh`.
* The `failureThreshold: 30` at line 344 is in the `reconfigure_parlant()` function, which is the **load testing mode** — a lower threshold is intentional since mock LLM starts faster than Vertex AI.

This is not configuration drift but an intentional design choice.

### 3.3 MongoDB Connection Storm (M0 Tier)

**Finding ID: OPS-003**

**Severity: P2 (High)**

The application connects to MongoDB Atlas Free Tier (M0), which has a hard limit of **500 connections**, but `production_config.py` does not set `maxPoolSize`.

**Impact:**

With the default pymongo pool size of 100, scaling beyond 5 pods (100 × 5 = 500) will exhaust connections, causing a total service outage.

**Fix:** Explicitly set `maxPoolSize=50` in the connection string or client options.

### 3.4 Deployment Model Mismatch

**Finding ID: OPS-004**

**Severity: P3 (Low)**

The `production_config.py` comments (line 35) document the default Vertex AI model as `claude-sonnet-3.5`, but `setup.sh` (line 437) deploys with `VERTEX_AI_MODEL=gemini-2.5-flash`.

**Impact:**

Documentation inaccuracy. Developers reading `production_config.py` will have a wrong expectation of which model is running in production.

**Fix:** Update the comment in `production_config.py` to reflect the actual deployed model, or parameterize the model choice more clearly.

---

## 4. Automated Remediation (Patches)

Apply these patches to fix the code vulnerabilities and configuration issues.

### Patch 1: Secure IAM & Fix UID Mismatch

**Files:** `setup-github-wif.sh`, `setup.sh`, `Dockerfile-GKE-Autopilot`

```diff
--- a/healthcare-agent-gke-autopilot/backend/setup-github-wif.sh
+++ b/healthcare-agent-gke-autopilot/backend/setup-github-wif.sh
@@ -111,3 +111,3 @@
     --member="serviceAccount:${SA_EMAIL}" \
-    --role="roles/artifactregistry.admin" \
+    --role="roles/artifactregistry.writer" \
     --quiet > /dev/null
```

```diff
--- a/healthcare-agent-gke-autopilot/backend/setup.sh
+++ b/healthcare-agent-gke-autopilot/backend/setup.sh
@@ -416,3 +416,3 @@
       securityContext:
         runAsNonRoot: true
-        runAsUser: 999
+        runAsUser: 1000
       containers:
```

```diff
--- a/healthcare-agent-gke-autopilot/backend/Dockerfile-GKE-Autopilot
+++ b/healthcare-agent-gke-autopilot/backend/Dockerfile-GKE-Autopilot
@@ -16,1 +16,1 @@
-RUN groupadd -r parlant && useradd -r -g parlant -m -d /home/parlant parlant
+RUN groupadd -r parlant && useradd -r -g parlant -u 1000 -m -d /home/parlant parlant
```

### ~~Patch 2: Fix Load Test Revert Drift~~ **[RETRACTED]**

**[CORRECTED]** This patch is unnecessary. The `revert_to_production()` function already sets `failureThreshold: 60` at line 198, matching `setup.sh`. No change needed.

### Patch 3: Secure Production Config (CORS & DB)

**Files:** `main.py`, `production_config.py`

```diff
--- a/healthcare-agent-gke-autopilot/backend/main.py
+++ b/healthcare-agent-gke-autopilot/backend/main.py
@@ -76,5 +76,6 @@
 async def configure_api(app: FastAPI) -> None:
+    origins = os.environ.get("ALLOWED_ORIGINS", "*").split(",")
     app.add_middleware(
         CORSMiddleware,
-        allow_origins=["*"],  # In production, specify your frontend domain
+        allow_origins=origins,
         allow_credentials=True,
```

```diff
--- a/healthcare-agent-gke-autopilot/backend/production_config.py
+++ b/healthcare-agent-gke-autopilot/backend/production_config.py
@@ -41,4 +41,6 @@
 def get_mongodb_config():
-    return {
-        "session_store": MONGODB_SESSIONS_URI,
-        "customer_store": MONGODB_CUSTOMERS_URI,
-    }
+    # Enforce pool limits for M0 tier (Limit 500 / 10 Pods = 50)
+    options = "?maxPoolSize=50"
+    return {
+        "session_store": f"{MONGODB_SESSIONS_URI}{options}",
+        "customer_store": f"{MONGODB_CUSTOMERS_URI}{options}",
+    }
```

---

## 5. Continuous Integration Strategy

This CI job automates the validation of these fixes using the project's existing scripts and static analysis.

```yaml
name: Secure CI/CD
on: [push, pull_request]

jobs:
  validate:
    name: Security & Config Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # 1. Static Analysis (IaC Security)
      - name: Run Checkov
        uses: bridgecrewio/checkov-action@master
        with:
          directory: healthcare-agent-gke-autopilot/
          framework: kubernetes
          quiet: true
          skip_check: CKV_K8S_21  # Allow default namespace for this specific app

      # 2. Logic & Syntax Check
      - name: Verify Shell Scripts
        run: |
          bash -n healthcare-agent-gke-autopilot/backend/verify.sh
          bash -n healthcare-agent-gke-autopilot/backend/setup.sh

      # 3. Connection Pool Safety Check (Custom)
      - name: Verify MongoDB Pool Config
        run: |
          if grep -q "maxPoolSize" healthcare-agent-gke-autopilot/backend/production_config.py; then
            echo "✅ maxPoolSize is configured."
          else
            echo "❌ CRITICAL: maxPoolSize missing in production_config.py"
            exit 1
          fi

      # 4. UID Consistency Check
      - name: Verify Container UID Alignment
        run: |
          DOCKER_UID=$(grep "useradd" healthcare-agent-gke-autopilot/backend/Dockerfile-GKE-Autopilot | grep -oP '\-u \K[0-9]+' | head -1)
          SETUP_UID=$(grep "runAsUser" healthcare-agent-gke-autopilot/backend/setup.sh | grep -o '[0-9]*' | head -1)

          if [ "$DOCKER_UID" == "$SETUP_UID" ]; then
             echo "✅ UID $DOCKER_UID matched in Dockerfile-GKE-Autopilot and setup.sh"
          else
             echo "❌ UID Mismatch: Dockerfile-GKE-Autopilot($DOCKER_UID) vs setup.sh($SETUP_UID)"
             exit 1
          fi
```

**[CORRECTED]** The original CI YAML had two issues:
1. A syntax error at the `if` statement (`if; then` instead of a proper conditional).
2. Referenced `Dockerfile` instead of `Dockerfile-GKE-Autopilot` (the actual production image).

---

## 6. Chaos & Load Testing Plan

Use the **existing** robust test suite located in `load_testing/`. Do not create new scripts.

**Scenario:** Validating System Recovery from Pod Loss (Chaos)

**Goal:** Ensure 50 Concurrent Users (CCU) experience no downtime during pod restarts.

**Execution Runbook:**

1. **Deploy Load Test Infra:**
   ```bash
   cd healthcare-agent-gke-autopilot/backend/load_testing
   ./run-scale-test.sh deploy
   ```
   *Note: This automatically deploys mock-llm, locust, and hpa.*

2. **Verify HPA Limits:**
   Ensure `hpa.yaml` respects the M0 constraint:
   ```yaml
   maxReplicas: 3  # MUST be <= 500 connections / 50 pool size = 10 pods
   ```

3. **Execute Chaos Test:**
   Run the pre-defined chaos scenario which deletes pods under load:
   ```bash
   ./run-scale-test.sh chaos
   ```

4. **Success Criteria:**
   * Locust failure rate < 1%.
   * All pods recover within 60s (verified by startupProbe threshold).
   * Mock LLM latency does not cause liveness probe failures.

---

## 7. Validation Report Template

### Validation Report: Healthcare Agent Backend

**Date:** ____________________

**Auditor:** ____________________

#### 1. Static Checks

* [ ] **UID Match:** Verified `Dockerfile-GKE-Autopilot` and `setup.sh` use the same UID.
* [ ] **IAM Roles:** Verified `setup-github-wif.sh` uses `artifactregistry.writer`.
* [ ] **DB Config:** Verified `maxPoolSize` present in `production_config.py`.

#### 2. Functional Checks

* [ ] **Streaming:** Confirmed SDK version or adapter supports streaming (output appears token-by-token).
* [ ] **CORS:** `curl -I -H "Origin: http://evil.com" ...` returns no `Access-Control` headers.

#### 3. Reliability Checks

* [ ] **Chaos Test:** `run-scale-test.sh chaos` completed with 0 downtime.
* [ ] **Revert Safety:** Ran `redeploy-for-load-testing.sh --revert` and verified `kubectl get deploy parlant -o yaml` shows `failureThreshold: 60`.

**Final Status:** PASS / FAIL